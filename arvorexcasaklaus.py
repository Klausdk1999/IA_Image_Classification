# -*- coding: utf-8 -*-
"""ArvoreXCasaKlaus.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17dNPzKTPhWyEth7A22Sh8xCJgTfCa_zn

# BLU8002 - IA
Objetivo
Criar modelo capaz de diferenciar imagens de árvores e casas.
Aluno: Klaus Dieter Kupper
Prof. Mauri Ferrandin

# Parte I - baixando um arquivo .zip do GoogleDrive e descompactando no espaço (disco) do colab. 

Para fazer o download vamos usar um programar chamado gdown que precisa ser instalado no ambiente. No colab, as instruções precedidas por ! são executadas como comandos do sistema operacional (no caso do colab é Linux).
"""

# install gdown (to easy download files on public shares no googledrive)
!pip install gdown

"""Uma vez instalado o gdown, usaremos ele para fazer downloado do arquivo exemplo.zip de um compartilhamento público (compartilhamento acessível apenas com o link) do GoogleDrive.

então basta substituir na URL abaixo que será usada pelo gdown o texto id_do_compartilhamento pelo id obtido: 

gdown https://drive.google.com/uc?id=id_do_compartilhamento

Abaixo o uso do gdown para este arquivo (exemplo.zip) com alguns comandos adicionais comentados no texto. Caso julgue interessante, separe cada comando em uma caixa para executá-lo em separado e ver o resultado que ele produz:
"""

# remover o Dataset_mod.zip caso já exista
!rm -rfv Dataset_mod.zip

# remover o diretório gerado ao descompactar o Dataset_mod.zip caso já exista
!rm -rfv Dataset_mod/

# baixar o arquivo do GoogleDrive usando o gdown
!gdown https://drive.google.com/uc?id=1KOE_X7hPZvy9vZLN7e0pqwkbidruLTeN

# descompactar o arquivo Dataset_mod.zip
!unzip -q Dataset_mod.zip

# listar os arquivos e diretórios
!ls -ltr

"""
# Parte II: Lendo os arquivos de entrada usando o ImageDataGenerator

A classe ImageDataGenerator que é parte da API do Keras é um componente de grande utilidade para carregar e fazer pré-processamento das imagens para uma rede neural programada com o Keras.

Além da função de ler os arquivos contendo as imagens com base em uma organização de diretórios, ele possuí outras funcionalidades de pré-processamento, como redimensionamento, rotação, zoom, resampling, etc. Para mais detalhes visite: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator.

Além do componente ImageDataGenerator, existem outros componentes e métodos para ler os dados de imagens e transformá-las em matrizes no formato necessário para usá-las em uma rede CNN. Um exemplo de outro componente é o [tf.keras.preprocessing.image_dataset_from_directory](https://keras.io/api/preprocessing/image/) entre outros.

Para usar o ImageDataGenerator, é preciso criar a seguinte estrutura de diretórios:


```
Dataset_mod/
├── test
│   ├── tree
│   │   ├── tree183.bmp
│   │   ├── tree184.bmp
│   │   ├── tree185.bmp
│   │   └── tree272.bmp
│   │   └── ...
│   └── house
│       ├── house333.bmp
│       ├── house 334.bmp
│       ├── house335.bmp
│       └── house418.bmp
│       └── ...
├── training_set
│   ├── tree
│   │   ├── tree_001.bmp
│   │   ├── tree_003.bmp
│   │   ├── tree_004.bmp
│   │   └── ...
│   └── house
│       ├── house10.jpg
│       ├── house11.jpg
│       ├── house14.jpg
│       └── ...
└── valid_set
    ├── tree
    │   ├── tree_002.bmp
    │   ├── tree_019.bmp
    │   ├── tree_020.bmp
    │   └── ...
    └── house
        ├── house12.jpg
        ├── house13.jpg
        ├── house2.jpg
        └── ...

```

Estando as imagens de cada grupo separadas (train, validation, test), basta usar o componente para ler e pré-processar as imagens de cada grupo indicando o diretório em que elas se encontram.

"""

from keras.preprocessing.image import ImageDataGenerator

# definindo o tamanho (tam x tam) que usaremos para as imagens na CNN, o componente já fará o redimensionamento delas.
tam = 100

# Instanciando um objeto para ler os exemplos de treinamento. Para os exemplos de treinamento, serão feitas algumas operações com as imagens.
gerador_treinamento = ImageDataGenerator(rescale = 1./255,
                                         rotation_range = 7,
                                         horizontal_flip = True,
                                         shear_range = 0.2,
                                         height_shift_range = 0.07,
                                         zoom_range = 0.2)

# Usando o objeto gerador_treinamento criado, faremos a carga de todas as imagens do diretório de treinamento. Os subdiretórios indicarão a que classe dada imagem pertence.
base_treinamento = gerador_treinamento.flow_from_directory('Dataset_mod/train',
                                                           target_size = (tam,tam),                                                           
                                                           batch_size=1000, 
                                                           class_mode = 'binary')


# Instanciando um objeto para ler os exemplos de validação e teste. Neste caso faremos apenas a normalização dos valores pois queremos que a rede reconheça as imagens sem pré-processá-las.
gerador_teste = ImageDataGenerator(rescale = 1./255)

# Fazendo a carga das imagens de validação
base_validacao = gerador_teste.flow_from_directory('Dataset_mod/validation',
                                                           target_size = (tam,tam),  
                                                            batch_size=1000,                                                          
                                                           class_mode = 'binary')
# Fazendo a carga das imagens de teste
base_teste = gerador_teste.flow_from_directory('Dataset_mod/test',
                                                           target_size = (tam,tam),  
                                                            batch_size=1000,                                                         
                                                           class_mode = 'binary')

"""# Parte III: definir a rede, treinar a rede, avaliar resultados

Para estas etapas, complete os blocos abaixo.
"""

# definir a CNN
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam

model = Sequential()

# definir as camadas
model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(tam, tam, 3)))

model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))

model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())

model.add(Dense(128, activation='relu'))

model.add(Dropout(0.5))

model.add(Dense(1, activation='sigmoid'))

model.summary()

# compilar treinar o modelo
model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])

# exemplo de como indicar os dados de entrada obtidos pelo ImageDataGenerator para treinamento e validação do modelo
hist = model.fit(base_treinamento, epochs=200, validation_data=base_validacao)

test_loss, test_accuracy = model.evaluate(base_teste)
print(f"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}")

# plotar as curvas - é preciso ajustar as séries de acordo com as métricas e loss function definidas na compilação do modelo
import matplotlib.pyplot as plt

# para ver as variáveis disponíveis no history
print(hist.history.keys())


# summarize history for accuracy
plt.plot(hist.history['accuracy'])
plt.plot(hist.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'valid'], loc='upper left')
plt.show()

# summarize history for loss
plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'valid'], loc='upper left')
plt.show()

# testando o desempenho do modelo sobre os exemplos de teste
score = model.evaluate(base_teste, verbose=0)
print("Test loss:", score[0])
print("Test accuracy:", score[1])

images, labels = next(base_teste)
print(images.shape)
print(labels.shape)


import matplotlib.pyplot as plt
import numpy as np


predictions = (model.predict(base_teste, verbose=0) > 0.5).astype(int)


plt.figure(figsize=(20, 20))
for i in range(25):
    ax = plt.subplot(5, 5, i + 1)
    plt.imshow(images[i])
    plt.title(list(base_teste.class_indices.keys())[labels[i].astype(int)] + "->" + list(base_teste.class_indices.keys())[predictions[i,0].astype(int)])    
    plt.axis("off")

print(np.column_stack((labels, predictions)))
